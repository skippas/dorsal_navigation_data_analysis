---
title: "data_analysis_2023"
author: "drdre"
date: '2023-08-17'
output: html_document
---

Data analysis 2023

```{r}
rm(list = ls())
source("loading_cleaning.R")

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

bin_fill <- c('1' = '#27b376', '0' = '#bf212f')
fill_scale <- scale_fill_manual(name = "first", values = bin_fill)
color_scale <- scale_color_manual(name = "first_decision", values = bin_fill)
grad_scale <- scale_colour_gradient2(low = bin_fill[2], high = bin_fill[1], 
                         midpoint = 0.5, limit = c(0,1), space = "Lab")

custom_theme_no_y_grid <- theme_minimal() +
  theme(
    panel.grid.major.y = element_blank(),  # Remove major horizontal grid lines
    panel.grid.minor.y = element_blank(),  # Remove minor horizontal grid lines
   )
custom_theme_no_x_grid <- theme_minimal() +
  theme(
    panel.grid.major.x = element_blank(),  # Remove major horizontal grid lines
    panel.grid.minor.x = element_blank(),  # Remove minor horizontal grid lines
   )
custom_theme_text_enlarged <- theme_minimal()+
  theme(
        axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14))
```


```{r}
# reorder individuals 
max_values <- choices %>%
  group_by(individual) %>%
  summarise(max_value = max(rank_trial)) %>%
  arrange(max_value)
# Reorder the levels of the individual factor based on the maximum values
choices$individual <- factor(choices$individual, levels = max_values$individual)

# below can be used to reassign sequential numerical codes for individuals
# choices <- choices %>%
#  mutate(individual = match(individual, unique(individual)))

# trial number needs to be per individual (experience)
# note that there was a training phase (this is an old comment, what does it mean, when were the training phases?!)
# and finally, some individuals came into experiment later and may have missed training phase?
# Where did the blocks occur? This might affect learning.
# remove illegible handwriting.

# performance across trials within experiments ####
# comparing thin stripe test and control

# one way of visualizing which trials are used in barplots of performance across groups of trials
# is by highlighting the groups with grey rectangles
choices_sub <- choices %>% filter(experiment == "thin_stripes",
                   individual %in% c('51', '2', '32', '55'))
ggplot(choices_sub, aes(y = individual, x = rank_trial, fill = as.character(first)))+
  geom_tile()+
  fill_scale+
  facet_wrap(facets = "experiment",  ncol = 2, scales = "free_y")+
# Add shaded areas for first n and last n trials. Could add lineranges instead
  geom_rect(data = choices_sub %>% filter(rank_trial <= 15),
            aes(xmin = rank_trial - 0.5, xmax = rank_trial + 0.5,
                ymin = as.numeric(factor(individual)) - 0.5,
                ymax = as.numeric(factor(individual)) + 0.5),
            fill = "grey30", alpha = 0.5, inherit.aes = FALSE) +
  geom_rect(data = choices_sub %>% group_by(individual) %>%
              filter(rank_trial > max(rank_trial) - 15),
            aes(xmin = rank_trial - 0.5, xmax = rank_trial + 0.5,
                ymin = as.numeric(factor(individual)) - 0.5,
                ymax = as.numeric(factor(individual)) + 0.5),
            fill = "grey30", alpha = 0.5, inherit.aes = FALSE)

# compare first n of test to last n of test and to the first ~15 of control

# Make a new variable 
choices <- choices %>%
  group_by(individual, experiment) %>%
  mutate(max_trial = max(rank_trial)) %>%
  ungroup() %>% # Add a new column to denote the trial group
  mutate(trial_group = case_when(
    rank_trial <= 15 ~ "first_n",
    rank_trial > max_trial - 15 ~ "last_n",
    TRUE ~ "inbetween"
  )) 
# change control to a trial group within experiment rather than an experiment
choices <- choices %>% ungroup %>%
  mutate(trial_group = if_else(experiment == 'control', 'control', trial_group),
         experiment = if_else(experiment == 'control', 'thin_stripes', experiment))


# first 15 group, inbetween trials, and last 15 group
# reset trial numbering within groups
choices <- choices %>% 
    group_by(experiment, individual, trial_group) %>% 
    arrange(rank_trial) %>% 
    mutate(rank_win_group = 1:n()) %>% 
    ungroup()



choices$trial_group = factor(choices$trial_group,
                             levels=c('first_n','inbetween', 'last_n', 'control'))

choices %>% filter(experiment == "thin_stripes", trial_group != 'inbetween',
                   individual %in% c('51', '2', '32', '55')) %>%
    ggplot(aes(y = individual, x = rank_win_group, fill = as.character(first)))+
  geom_tile()+
  fill_scale+
  facet_wrap(facets = "trial_group",  ncol = 4, scales = "free_x")

# Calculate the proportion of correct decisions for each trial group
proportion_data <- choices %>%
  filter(experiment == "thin_stripes", trial_group != 'inbetween') %>%
  group_by(trial_group, first) %>%
  summarise(cases = n()) %>%
  mutate(total = sum(cases)) %>%
  rowwise() %>%
  mutate(tst = list(broom::tidy(prop.test(cases, total, conf.level=0.95)))) %>%
  tidyr::unnest(tst)

# plot proportion correct across individuals for different trial groups with CIs
ggplot(proportion_data, aes(x = trial_group, y = estimate, fill = as.character(first)))+ 
  geom_col(position =  position_dodge())+
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high),
                position = position_dodge2( width = 0.7, padding = 0.7))+
  geom_hline(lty = 2, yintercept = 0.5)+
  scale_fill_manual(values = c("1" = '#27b376', '0' = '#bf212f'))+
  scale_y_continuous(labels=scales::percent)+
  theme_classic()+
  facet_wrap(facets = "trial_group", scales = 'free_x', ncol = 4)
# perhaps plot trial groups separately for easier manipulation in inkscape
# also need to modify tile plots so the trials used for each individual is clear.
# repeat this figure across experiments
# make learning rate figure

# alternate version of above tileplot for vg present
perp_para %>%
  filter(individual %in% c("13", "51", "53")) %>% 
  mutate(first = as.character(first),
                     individual = factor(individual, levels = 
                                              c("13", "51", "53")),
                   stimuli = factor(stimuli, levels = rev(c("test","ctrl")))) 

choices %>% 
  filter(experiment != "thick_stripe") %>%
  mutate(first = as.character(first),
         individual = factor(individual,
                             levels = rev(c("2", "11", "31", "32", "33", "51", "55"))),
                   experiment = factor(
                     experiment, levels = rev(c("thick_stripe",
                                            "thin_stripes",
                                            "control")))) %>%
  ggplot(aes(y = experiment, x = rank_trial, fill = first))+
  geom_tile()+
    scale_fill_manual(values = c("0" = "#e41a1c", "1" = "#4daf4a"), 
                    breaks = c( "1","0"), 
                    labels = c("Correct", "Incorrect"))+
  scale_y_discrete(labels = c("Control", "Test"))+
  labs(x = "Trial", y = "Experiment", fill = "First decision")+
  facet_wrap(facets = "individual",  ncol = 1, scales = "free_y",
             labeller = labeller(individual = ~ paste("Individual: ", .),
                                 .multi_line = F))
  ggsave("figures//optflow_tileplot_vg_version.png", plot = last_plot(), width = 6, height = 8, dpi = 300)

# average decision accuracies across all trials for each experiment #

# not a reflection of their optimal decision accuracy as it includes a learning phase and logistic regression seems to suggest there is an effect of trial number
# Most of this code below is just a poor way of showing the data and can probs be deleted as its better above

# Calculate the proportion of correct decisions for each experiment
# More formulaic way of calculating confidence intervals
# alpha <- 0.95 # Confidence level
# z_value <- qnorm((1 + alpha) / 2) # Z-value for confidence interval
# proportion_data <- proportion_data %>%
#   mutate(se = sqrt(proportion_correct * (1 - proportion_correct) / n),
#          conf_interval = z_value * se)

### Comparing thick_stripe and thin stripe performance ####
# bar plot with CIs
ggplot(proportion_data, aes(x = experiment, y = proportion_correct)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = proportion_correct - conf_interval, ymax = proportion_correct + conf_interval),
                position = position_dodge(width = 0.8), width = 0.2) +
  labs(x = "Experiment", y = "Proportion Correct") 

# comparing thin stripes control to testing phase. 
proportion_data %>% filter(experiment != "thick_stripe") %>%
ggplot(aes(x = experiment, y = proportion_correct)) +
  geom_point(size = 3)+
  geom_hline(yintercept = 0.5, lty = 2)+
  scale_y_continuous(labels = scales::percent)+
  geom_errorbar(aes(ymin = proportion_correct - conf_interval, ymax = proportion_correct + conf_interval),
                position = position_dodge(width = 0.8), width = 0.2) +
  labs(x = "Experiment", y = "Percent correct decisions") +
  theme_minimal()+
  custom_theme_text_enlarged+
    scale_x_discrete(labels = c("Test", "Control", "Thick stripe"))
ggsave("figures//optflow_point_and_errorbars.png", plot = last_plot(), width = 4, height = 3, dpi = 300)

```

```{r}

#### base plot proving to be a bit difficult, so moving back to ggplot ####

thick <- choices %>% filter(experiment == "thick_stripe")
thin <- choices %>% filter(experiment == "thin_stripes")

m_thick <- glm(first ~ rank_trial, data = thick, family = binomial)
m_thin <- glm(first ~ rank_trial, data = thin, family = binomial)
summary(m_thin)

thick$pred_prob <- predict(m_thick, type = "response")
thin$pred_prob <- predict(m_thin, type = "response")

combined_data <- bind_rows(#thick %>% select(first, rank_trial, pred_prob),
                           thin %>% select(first, rank_trial, pred_prob))

ggplot(combined_data, aes(x = rank_trial, y = pred_prob)) +
  geom_smooth(method = "loess", se = FALSE) +
  geom_smooth(method = "glm", method.args = list(family = binomial),
              fill = "grey", colour = "black", alpha = 0.5) +
    geom_hline(yintercept = 0.5, lty = 2)+
  labs(x = "Trial", y = "Predicted Probability") +
  theme_minimal()+
  theme(axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14))
ggsave("figures//optflow_log_reg_thin_stripes.png", plot = last_plot(), width = 5, height = 3, dpi = 300)

# visualize how proportion correct changes across trial ####
choices %>% filter(experiment == "thick_stripe") %>%
  group_by(rank_trial, first) %>%
  summarise(count = n()) %>%
  group_by(rank_trial) %>%
  mutate(proportion = count / sum(count),
         first = as.character(first)) %>%
  ggplot(aes(x = rank_trial, y = proportion, fill = first)) +
  geom_col(position = "fill")+
  geom_hline(yintercept = 0.5, lty = 2)+
  scale_y_continuous(labels = scales::percent)+
  scale_fill_manual(values = c("0" = "#e41a1c", "1" = "#4daf4a"), 
                    breaks = c( "1","0"), 
                    labels = c("Correct", "Incorrect"))+
  labs(fill = "First decision", x = "Trial", y = "Percent of decisions correct / incorrect")+
  theme_minimal()+
  theme(axis.title.x = element_text(size = 14),  
        axis.title.y = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 14))  
ggsave("figures//my_plot.png", plot = last_plot(), width = 10, height = 6, dpi = 300)

# first 10 versus last 10

# repeat for the relevant experiments

# some stats

```

parallel versus perpendicular results

```{r}

# Tile plot ####
facet_labels <- c(thin_stripes = "multiple thin 45 degree stripes",
                          thick_stripe = "single thick stripe",
                          control = "control")

perp_para %>%
  filter(individual %in% c("13", "51", "53")) %>% 
  mutate(first = as.character(first),
                     individual = factor(individual, levels = 
                                              rev(c("13", "51", "53"))),
                   stimuli = factor(stimuli, levels = rev(c("test","ctrl")))) %>%
  ggplot(aes(y = stimuli, x = rank_trial, fill = first))+
  geom_tile()+
  facet_wrap(~ individual,  ncol = 1,
             labeller = labeller(individual = ~ paste("Individual: ", .),
                                 .multi_line = F),
             scales = "free_y")+
  labs(x = "Trial", y = "Experiment", fill = "Choice")+
  scale_fill_manual(values = c("0" = "#e41a1c", "1" = "#4daf4a"), 
                    breaks = c( "1","0"), 
                    labels = c("Rewarding", "Unrewarding"))+
  scale_y_discrete(labels = c("Control", "Test"))+
  theme_bw()+
  theme(panel.grid = element_blank(),
        legend.position = "top",
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14))
ggsave("figures//perppara_tileplot.png", plot = last_plot(), width = 6, height = 6, dpi = 300)


# point plot with confidence intervals ####

proportion_data <- perp_para %>%
  group_by(stimuli) %>%
  summarise(proportion_correct = mean(first, na.rm = T),
            n = n())
# Calculate the confidence intervals
alpha <- 0.95 # Confidence level
z_value <- qnorm((1 + alpha) / 2) # Z-value for confidence interval
proportion_data <- proportion_data %>%
  mutate(se = sqrt(proportion_correct * (1 - proportion_correct) / n),
         conf_interval = z_value * se)

proportion_data %>% 
  mutate(stimuli = factor(stimuli, levels = c("test","ctrl"))) %>%
ggplot(aes(x = stimuli, y = proportion_correct)) +
  geom_point(size = 3)+
  geom_hline(yintercept = 0.5, lty = 2)+
  scale_y_continuous(labels = scales::percent)+
      scale_x_discrete(labels = c("Test", "Control"))+
  geom_errorbar(aes(ymin = proportion_correct - conf_interval, ymax = proportion_correct + conf_interval),
                position = position_dodge(width = 0.8), width = 0.2) +
  labs(y = "Percent correct decisions") +
  theme_minimal()+
  theme(axis.title.x = element_blank(),  
        axis.title.y = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 14))+
ggsave("figures//perppara_point_and_errorbars.png", plot = last_plot(), width = 3, height = 3, dpi = 300)

# logistic regression with ggplot ####

test <- perp_para %>% filter(stimuli == "test")
ctrl <- perp_para %>% filter(stimuli == "ctrl")

m_test <- glm(first ~ rank_trial, data = test, family = binomial)
m_ctrl <- glm(first ~ rank_trial, data = ctrl, family = binomial)
summary(m_test)
summary(m_ctrl)

test$pred_prob <- predict(m_test, type = "response")
ctrl$pred_prob <- predict(m_ctrl, type = "response")

combined_data <- bind_rows(test %>% select(first, rank_trial, pred_prob),
                           ctrl %>% select(first, rank_trial, pred_prob))
combined_data %>% filter(stimuli == "test") %>% 
  ggplot(aes(x = rank_trial, y = pred_prob)) +
  geom_smooth(method = "loess", se = FALSE) +
  geom_smooth(method = "glm", method.args = list(family = binomial),
             colour = "black", fill = "grey", alpha = 0.2) +
  geom_hline(yintercept = 0.5, lty = 2)+
  labs(x = "Trial", y = "Predicted probability\ncorrect decision") +
  scale_color_manual(values = c("red", "green", "blue")) +
  theme_minimal()+
  theme(axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14))
ggsave("figures//perppara_log_reg.png", plot = last_plot(), width = 5, height = 3, dpi = 300)



```


## Things to think about
What is the effect of the blocking I've been doing? I haven't had a very firm or consistant rule about blocking except that I do it after an individual makes consistant mistakes in one direction and appears to have a side bias. I think its important to think about because its a very effective way to teach the wasp or to accelerate its learning. I use blocking with the intention of showing the wasp that it can turn the other direction and still receive the reward. I believe that insects might need to learn to override a consistant motor command, or perhaps to learn that varying the motor commands is more effective (more rewarding) than using one motor command exclusively. I think that the wasp might need to be shown that two paths exist and that one path always contains the reward. If the wasp is not shown this, then all it knows is that it is receiving rewards in a somewhat idiosyncratic way. Perhaps the wasp does 'notice' that the pattern overhead signifies the presence of reward or the lack thereof. But it surely doesn't know that the reward exists in the other arm when it is not present in this arm. How could it? Unless it has some in-built mechanism that informs steering commands when a snapshot is not matched. This makes me wonder, what happens if you just have one arm and change the patterns and reward? Will the wasp ever learn to turn around, or increase its turning around over time? Or can this only happen when the wasp also learns that there is another location to turn around and go to? 

If the wasp learns that there are two locations, does this heighten its sensitivity to the differences in the two dorsal patterns? I'm wondering if when there is only one arm / location the wasp is less sensitive to changes in the pattern because these changes can and do happen in nature.

- I should account for side bias in my analyses. One effect of side bias in combination with an unequal number of trials will be an over / underestimate of decision accuracy. How can I account for too many trials on one side? I need to weight the trials from each side equally...

- there are important decisions to make around which individuals to include seeing as some came into experiments at different times and may have had side preferences for longer. Im thinking #31 from recent experiments where I had too many individuals to give it proper attention and eradicate its side preference rapidly. One solution may be to analyze results with different subsets of individuals and to see whether it affects inferences.

- I wonder if its not just the accuracy of first decisions that changes when you chang from patterns to no patterns but also the total number of incorrect decisions? ie do they go the same, wrong way a lot more when no patterns in? What does this mean?

- humans can probably learn thousands of faces, insects can probably learn thousands of snapshots. can I learn anything from the human face recognition literature?

- i wouldnt jump to the conclusion that many thin stripes is more difficult than thick stripes just from this data because thick stripes had a training session not included in the data, which could bias the proportion correct upwards.

- is it really true that insects get better across trials? or is this just an effect of averaging across insects and rather there is a distinct moment that each insect 'gets it'? Would an interaction between trial and individual perhaps account for this? I haven't thought much about what the different models would be testing. 

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


TO DO:
0. enter data and plot previous experiments. particularly interested in seeing the first control. make note of the fact that training procedures have changed...
1. make tile plot for the cohort across thick stripe, multi small stripe and control. would be nice to annotate the onset of different days and experiments. 

INF. revisit logistic regression basics to understand the stats.

INF. visualize proportion correct of thick stripe, mulitple small stripes, and control.
next, think about logistic regression and learning rates.

INF. change name of 'choices' to reflect the experiment. eg. angled is a better name. If i'm still separating datasets by experiment.


```{r}
# old attempt making log reg curves with base R

# get rid of NAs in data so it plays nice with min and max functions. 
# could also use na.rm = T in the functions, but NAs may cause problems anywhere
# need to look into NAs and remove / change them earlier.

### base plot effort ####
# logit = function(x) log(x/(1-x))
# invlogit = function(x) 1/(1+exp(-x))
# 
# # Fit logistic regression model for each experiment
# m_thick <- glm(first ~ rank_trial,
#                data = choices[choices$experiment == "thick_stripe",],
#                family = binomial)
# m_thin <- glm(first ~ rank_trial,
#               data = choices[choices$experiment == "thin_stripes",],
#               family = binomial)
# m_ctrl <- glm(first ~ rank_trial,
#               data = choices[choices$experiment == "control",],
#               family = binomial)
# # Summary of the model
# summary(m_thick)
# summary(m_thin)
# summary(m_ctrl)

# thin stripe regression
#pdf("figures//my_base_plot.pdf", width = 8, height = 6)

thin_x_pred = with(choices[choices$experiment == "thin_stripes", ], seq(from=min(rank_trial), to=max(rank_trial), by=0.01))

with(choices[choices$experiment == "thin_stripes",],
     plot(x = c(min(rank_trial), max(rank_trial)),
          y = c(0, 1), type = "n", xlab = "Trial", ylab = "Predicted probability of correct decision"))

thin_predicted_probs <- predict(m_thin, newdata=list(rank_trial=thin_x_pred),  type = "response", se.fit = TRUE)
lines(thin_x_pred, thin_predicted_probs$fit)
polygon(c(thin_x_pred, rev(thin_x_pred)),
        c(thin_predicted_probs$fit+1.96*thin_predicted_probs$se.fit, 
                          rev(thin_predicted_probs$fit-1.96*thin_predicted_probs$se.fit)), 
        col = rgb(0,.3,1,.5), border = FALSE)
dev.off()
# thick
x_pred = with(choices[choices$experiment == "thick_stripe", ], seq(from=min(rank_trial), to=max(rank_trial), by=0.01))

with(choices[choices$experiment == "thick_stripe",],
     plot(x = c(min(rank_trial), max(rank_trial)),
          y = c(0, 1), type = "n", xlab = "Trial", ylab = "Predicted probability of correct decision"))

predicted_probs <- predict(m_thick, newdata=list(rank_trial=x_pred),  type = "response", se.fit = TRUE)

lines(x_pred, predicted_probs$fit)
polygon(c(x_pred, rev(x_pred)),
        c(predicted_probs$fit+1.96*predicted_probs$se.fit, 
                          rev(predicted_probs$fit-1.96*predicted_probs$se.fit)), 
        col = rgb(0,1,0,.5), border = FALSE)

# control 
ctrl_x_pred = with(choices[choices$experiment == "control", ], seq(from=min(rank_trial), to=max(rank_trial), by=0.01))

with(choices[choices$experiment == "thick_stripe",],
     plot(x = c(min(rank_trial), max(rank_trial)),
          y = c(0, 1), type = "n", xlab = "Trial", ylab = "Predicted probability of correct decision"))

ctrl_predicted_probs <- predict(m_ctrl, newdata=list(rank_trial=ctrl_x_pred),  type = "response", se.fit = TRUE)

lines(ctrl_x_pred, ctrl_predicted_probs$fit)
polygon(c(ctrl_x_pred, rev(ctrl_x_pred)),
        c(ctrl_predicted_probs$fit+1.96*ctrl_predicted_probs$se.fit,
          rev(ctrl_predicted_probs$fit-1.96*ctrl_predicted_probs$se.fit)), 
        col = rgb(1,0,0,.5), border = FALSE)

rm(ctrl_x_pred, thin_x_pred, thin_predicted_probs, ctrl_predicted_probs, 
   predicted_probs, x_pred)


```