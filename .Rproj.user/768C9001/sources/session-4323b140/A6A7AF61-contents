---
title: "data_analysis_2023"
author: "drdre"
date: '2023-08-17'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

bin_fill <- c('1' = '#27b376', '0' = '#bf212f')
fill_scale <- scale_fill_manual(name = "first", values = bin_fill)
color_scale <- scale_color_manual(name = "first_decision", values = bin_fill)
grad_scale <- scale_colour_gradient2(low = bin_fill[2], high = bin_fill[1], 
                         midpoint = 0.5, limit = c(0,1), space = "Lab")

custom_theme <- theme_minimal() +
  theme(
    panel.grid.major.y = element_blank(),  # Remove major horizontal grid lines
    panel.grid.minor.y = element_blank(),  # Remove minor horizontal grid lines
   )
theme_set(custom_theme)
theme

```

Data analysis 2023

```{r}
rm(list = ls())
source("loading_cleaning.R")

```

```{r}
# reorder individuals 
max_values <- choices %>%
  group_by(individual) %>%
  summarise(max_value = max(rank_trial)) %>%
  arrange(max_value)
# Reorder the levels of the individual factor based on the maximum values
choices$individual <- factor(choices$individual, levels = max_values$individual)
# below can be used to reassign sequential numerical codes for individuals
#choices <- choices %>%
#  mutate(individual = match(individual, unique(individual)))

# trial number needs to be per individual (experience)
# note that there was a training phase (this is an old comment, what does it mean, when were the training phases?!)
# and finally, some individuals came into experiment later and may have missed training phase?
# Where did the blocks occur? This might affect learning.
# remove illegible handwriting.

# tile plot ####
# comparing thin stripe test and control
x <- choices %>% filter(experiment == "thin_stripes", individual %in% c('51', '2', '32', '55'))
ggplot(x, aes(y = individual, x = rank_trial, fill = as.character(first)))+
  geom_tile()+
  fill_scale+
  facet_wrap(facets = "experiment",  ncol = 2, scales = "free_y")
# Add shaded areas for first 30 and last 30 trials
tp + 
  geom_rect(data = x %>% filter(rank_trial <= 15),
            aes(xmin = rank_trial - 0.5, xmax = rank_trial + 0.5,
                ymin = as.numeric(factor(individual)) - 0.5,
                ymax = as.numeric(factor(individual)) + 0.5),
            fill = "grey30", alpha = 0.5, inherit.aes = FALSE) +
  geom_rect(data = x %>% group_by(individual) %>%
              filter(rank_trial > max(rank_trial) - 15),
            aes(xmin = rank_trial - 0.5, xmax = rank_trial + 0.5,
                ymin = as.numeric(factor(individual)) - 0.5,
                ymax = as.numeric(factor(individual)) + 0.5),
            fill = "grey30", alpha = 0.5, inherit.aes = FALSE)

# compare first n of test to last n of test and to the first ~15 of control
# Add a new column for the maximum trial number for each individual
choices <- choices %>%
  group_by(individual) %>%
  mutate(max_trial = max(rank_trial)) %>%
  ungroup() %>% # Add a new column to denote the trial group
  mutate(trial_group = case_when(
    rank_trial <= 15 ~ "first_n",
    rank_trial > max_trial - 15 ~ "last_n",
    TRUE ~ "inbetween"
  )) 

# slightly diff tile plot:
# first 15 group, inbetween trials, and last 15 group
# reset trial numbering within groups
choices <- choices %>% 
    group_by(experiment, individual, trial_group) %>% 
    arrange(rank_trial) %>% 
    mutate(rank_win_group = 1:n()) %>% 
    ungroup()

choices$trial_group = factor(choices$trial_group,
                             levels=c('first_n','inbetween', 'last_n'))

choices %>% filter(experiment == "thin_stripes", individual %in% c('51', '2', '32', '55')) %>%
    ggplot(aes(y = individual, x = rank_win_group, fill = as.character(first)))+
  geom_tile()+
  fill_scale+
  facet_wrap(facets = "trial_group",  ncol = 3, scales = "free_x")

# Calculate the proportion of correct decisions for each trial group
# proportion_table <- choices %>%
#   group_by(individual, trial_group) %>%
#   summarise(correct = sum(decision == 1), total = n()) %>%
#   mutate(prop_corr = correct / total,
#          prop_incorr = 1 - prop_corr) %>%
#   group_by(trial_group) %>%
#   summarise(prop_corr = mean(prop_corr),
#             prop_incorr = mean(prop_incorr)) 
props[3,]
as.data.frame(props)
tidy(props)
prop.test(props[1,])
props <- table(choices$trial_group, choices$first, choices$experiment)[,,'thin_stripes']
library(broom)
broom::glance(prop.test(as.table(rev(props[3,]))))
broom::glance(prop.test(as.table(props[3,1:2])))


prop.test(as.table(rev(table(choices$trial_group, choices$first, choices$experiment)[3,,'thin_stripes'])))

binom.test(rev(table(choices$trial_group, choices$first, choices$experiment)[3,,'thin_stripes']))
prop_results <- prop.test(as.table(rev(table(choices$trial_group, choices$first, choices$experiment)[3,,'thin_stripes'])))

prop_ci<- prop_results$conf.int[1:2]
# plot data
proportion_table %>% filter(trial_group != "other") %>% 
  pivot_longer(cols = contains("prop"), values_to = "proportion", names_to = "decision") %>%
  ggplot(aes(x = trial_group, y = proportion, fill = decision))+ 
   geom_col(position =  position_dodge())+
    scale_y_continuous(labels=scales::percent)+
  scale_fill_manual(values = c("prop_corr" = '#27b376', 'prop_incorr' = '#bf212f'))+
  custom_theme
# perhaps plot trial groups separately for easier manipulation in inkscape
# also need to modify tile plots so the trials used for each individual is clear.
# repeat this figure across experiments
# make learning rate figure

# tile plot faceted by the trial group 


x<- choices %>% filter(experiment == "thin_stripes", trial_group == "last_30") %>%
  mutate(individual = as.factor(individual))
ggplot(droplevels(x), aes(y = individual, x = rank_trial, fill = as.character(first)))+
  geom_tile()+
  fill_scale+
  scale_x_continuous(breaks = scales::break(5))+
  facet_wrap(ncol = 1, vars(individual),
             scales = "free",  drop = T)+
  custom_theme +  theme(strip.text = element_blank())


facet_labels <- c(thin_stripes = "multiple thin 45 degree stripes",
                          thick_stripe = "single thick stripe",
                          control = "control")
choices %>% mutate(first = as.character(first),
                   experiment = factor(
                     experiment, levels = c("thick_stripe",
                                            "thin_stripes",
                                            "control"))) %>%
  ggplot(aes(y = individual, x = rank_trial, fill = first))+
  geom_tile()+
  facet_wrap(facets = "experiment",  ncol = 1, scales = "free_y",
             labeller = labeller(experiment = facet_labels))+
  fill_scale
  
# alternate version of above tileplot for vg present ####
perp_para %>%
  filter(individual %in% c("13", "51", "53")) %>% 
  mutate(first = as.character(first),
                     individual = factor(individual, levels = 
                                              c("13", "51", "53")),
                   stimuli = factor(stimuli, levels = rev(c("test","ctrl")))) 

  choices %>% 
  filter(experiment != "thick_stripe") %>%
  mutate(first = as.character(first),
         individual = factor(individual,
                             levels = rev(c("2", "11", "31", "32", "33", "51", "55"))),
                   experiment = factor(
                     experiment, levels = rev(c("thick_stripe",
                                            "thin_stripes",
                                            "control")))) %>%
  ggplot(aes(y = experiment, x = rank_trial, fill = first))+
  geom_tile()+
    scale_fill_manual(values = c("0" = "#e41a1c", "1" = "#4daf4a"), 
                    breaks = c( "1","0"), 
                    labels = c("Correct", "Incorrect"))+
  scale_y_discrete(labels = c("Control", "Test"))+
  labs(x = "Trial", y = "Experiment", fill = "First decision")+
  facet_wrap(facets = "individual",  ncol = 1, scales = "free_y",
             labeller = labeller(individual = ~ paste("Individual: ", .),
                                 .multi_line = F))+
    theme_bw()+
  theme(legend.position = "top",
        panel.grid = element_blank(),
        axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14))
  ggsave("figures//optflow_tileplot_vg_version.png", plot = last_plot(), width = 6, height = 8, dpi = 300)

# first half of trials versus last half of trials ####
## we need a variable saying which trials are below half of the max and which are above
choices <- choices %>%
  group_by(experiment) %>%
  mutate(midpoint = ceiling(max(rank_trial) / 2))

# Create a new variable 'trial_half' based on trial_number and experiment
choices <- choices %>%
  mutate(trial_half = ifelse(rank_trial <= midpoint, "first_half", "second_half"))

choices %>% group_by(experiment, trial_half, individual) %>%
    summarise(proportion_correct = mean(first)) %>%
  ggplot(aes(x = individual, y = proportion_correct, fill = trial_half))+
    geom_bar(position="dodge", stat="identity")+
  facet_wrap(facets = "experiment", ncol = 1)

# if we average over individuals it looks a bit cleaner.
choices %>% group_by(experiment, trial_half) %>%
    summarise(proportion_correct = mean(first, na.rm = T)) %>%
  ggplot(aes(x = trial_half, fill = trial_half, y = proportion_correct))+
    geom_bar(position="dodge", stat="identity")+
  facet_wrap(facets = "experiment", ncol = 1)
# To do:
## reorder experiments
## relabel experiments

# average decision accuracies across all trials ####
# overall decision accuracies. this is not a reflection of their optimal decision accuracy as it includes a learning phase and logistic regression seems to suggest there is an effect of trial number
# Calculate the proportion of correct decisions for each experiment
proportion_data <- choices %>%
  group_by(experiment) %>%
  summarise(proportion_correct = mean(first, na.rm = T),
            n = n())

# Calculate the confidence intervals using broom::tidy
# confidence_intervals <- proportion_data %>%
#   mutate(se = sqrt(proportion_correct * (1 - proportion_correct) / n)) %>%
#   tidy(conf.int = TRUE, conf.method = "wald")

# Calculate the confidence intervals
alpha <- 0.95 # Confidence level
z_value <- qnorm((1 + alpha) / 2) # Z-value for confidence interval
proportion_data <- proportion_data %>%
  mutate(se = sqrt(proportion_correct * (1 - proportion_correct) / n),
         conf_interval = z_value * se)

### Create a bar / point plot with confidence intervals ####

# bar
ggplot(proportion_data, aes(x = experiment, y = proportion_correct)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = proportion_correct - conf_interval, ymax = proportion_correct + conf_interval),
                position = position_dodge(width = 0.8), width = 0.2) +
  labs(x = "Experiment", y = "Proportion Correct") +
  custom_theme

# point and errors
proportion_data %>% filter(experiment != "thick_stripe") %>%
ggplot(aes(x = experiment, y = proportion_correct)) +
  geom_point(size = 3)+
  geom_hline(yintercept = 0.5, lty = 2)+
  scale_y_continuous(labels = scales::percent)+
  geom_errorbar(aes(ymin = proportion_correct - conf_interval, ymax = proportion_correct + conf_interval),
                position = position_dodge(width = 0.8), width = 0.2) +
  labs(x = "Experiment", y = "Percent correct decisions") +
  theme_minimal()+
  theme(axis.title.x = element_blank(),  
        axis.title.y = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 14))+
    scale_x_discrete(labels = c("Test", "Control", "Thick stripe"))
ggsave("figures//optflow_point_and_errorbars.png", plot = last_plot(), width = 4, height = 3, dpi = 300)

```

```{r}
# get rid of NAs in data so it plays nice with min and max functions. 
# could also use na.rm = T in the functions, but NAs may cause problems anywhere
# need to look into NAs and remove / change them earlier.

### base plot effort ####
logit = function(x) log(x/(1-x))
invlogit = function(x) 1/(1+exp(-x))

# Fit logistic regression model for each experiment
m_thick <- glm(first ~ rank_trial,
               data = choices[choices$experiment == "thick_stripe",],
               family = binomial)
m_thin <- glm(first ~ rank_trial,
              data = choices[choices$experiment == "thin_stripes",],
              family = binomial)
m_ctrl <- glm(first ~ rank_trial,
              data = choices[choices$experiment == "control",],
              family = binomial)
# Summary of the model
summary(m_thick)
summary(m_thin)
summary(m_ctrl)

# thin stripe regression
pdf("figures//my_base_plot.pdf", width = 8, height = 6)

thin_x_pred = with(choices[choices$experiment == "thin_stripes", ], seq(from=min(rank_trial), to=max(rank_trial), by=0.01))

with(choices[choices$experiment == "thin_stripes",],
     plot(x = c(min(rank_trial), max(rank_trial)),
          y = c(0, 1), type = "n", xlab = "Trial", ylab = "Predicted probability of correct decision"))

thin_predicted_probs <- predict(m_thin, newdata=list(rank_trial=thin_x_pred),  type = "response", se.fit = TRUE)
lines(thin_x_pred, thin_predicted_probs$fit)
polygon(c(thin_x_pred, rev(thin_x_pred)),
        c(thin_predicted_probs$fit+1.96*thin_predicted_probs$se.fit, 
                          rev(thin_predicted_probs$fit-1.96*thin_predicted_probs$se.fit)), 
        col = rgb(0,.3,1,.5), border = FALSE)
dev.off()
# thick
x_pred = with(choices[choices$experiment == "thick_stripe", ], seq(from=min(rank_trial), to=max(rank_trial), by=0.01))

with(choices[choices$experiment == "thick_stripe",],
     plot(x = c(min(rank_trial), max(rank_trial)),
          y = c(0, 1), type = "n", xlab = "Trial", ylab = "Predicted probability of correct decision"))

predicted_probs <- predict(m_thick, newdata=list(rank_trial=x_pred),  type = "response", se.fit = TRUE)

lines(x_pred, predicted_probs$fit)
polygon(c(x_pred, rev(x_pred)),
        c(predicted_probs$fit+1.96*predicted_probs$se.fit, 
                          rev(predicted_probs$fit-1.96*predicted_probs$se.fit)), 
        col = rgb(0,1,0,.5), border = FALSE)

# control 
ctrl_x_pred = with(choices[choices$experiment == "control", ], seq(from=min(rank_trial), to=max(rank_trial), by=0.01))

with(choices[choices$experiment == "thick_stripe",],
     plot(x = c(min(rank_trial), max(rank_trial)),
          y = c(0, 1), type = "n", xlab = "Trial", ylab = "Predicted probability of correct decision"))

ctrl_predicted_probs <- predict(m_ctrl, newdata=list(rank_trial=ctrl_x_pred),  type = "response", se.fit = TRUE)

lines(ctrl_x_pred, ctrl_predicted_probs$fit)
polygon(c(ctrl_x_pred, rev(ctrl_x_pred)),
        c(ctrl_predicted_probs$fit+1.96*ctrl_predicted_probs$se.fit,
          rev(ctrl_predicted_probs$fit-1.96*ctrl_predicted_probs$se.fit)), 
        col = rgb(1,0,0,.5), border = FALSE)

rm(ctrl_x_pred, thin_x_pred, thin_predicted_probs, ctrl_predicted_probs, 
   predicted_probs, x_pred)

#### base plot proving to be a bit difficult, so moving back to ggplot ####

thick <- choices %>% filter(experiment == "thick_stripe")
thin <- choices %>% filter(experiment == "thin_stripes")

m_thick <- glm(first ~ rank_trial, data = thick, family = binomial)
m_thin <- glm(first ~ rank_trial, data = thin, family = binomial)
summary(m_thin)

thick$pred_prob <- predict(m_thick, type = "response")
thin$pred_prob <- predict(m_thin, type = "response")

combined_data <- bind_rows(#thick %>% select(first, rank_trial, pred_prob),
                           thin %>% select(first, rank_trial, pred_prob))

ggplot(combined_data, aes(x = rank_trial, y = pred_prob)) +
  geom_smooth(method = "loess", se = FALSE) +
  geom_smooth(method = "glm", method.args = list(family = binomial),
              fill = "grey", colour = "black", alpha = 0.5) +
    geom_hline(yintercept = 0.5, lty = 2)+
  labs(x = "Trial", y = "Predicted Probability") +
  theme_minimal()+
  theme(axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14))
ggsave("figures//optflow_log_reg_thin_stripes.png", plot = last_plot(), width = 5, height = 3, dpi = 300)

# visualize how proportion correct changes across trial ####
choices %>% filter(experiment == "thick_stripe") %>%
  group_by(rank_trial, first) %>%
  summarise(count = n()) %>%
  group_by(rank_trial) %>%
  mutate(proportion = count / sum(count),
         first = as.character(first)) %>%
  ggplot(aes(x = rank_trial, y = proportion, fill = first)) +
  geom_col(position = "fill")+
  geom_hline(yintercept = 0.5, lty = 2)+
  scale_y_continuous(labels = scales::percent)+
  scale_fill_manual(values = c("0" = "#e41a1c", "1" = "#4daf4a"), 
                    breaks = c( "1","0"), 
                    labels = c("Correct", "Incorrect"))+
  labs(fill = "First decision", x = "Trial", y = "Percent of decisions correct / incorrect")+
  theme_minimal()+
  theme(axis.title.x = element_text(size = 14),  
        axis.title.y = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 14))  
ggsave("figures//my_plot.png", plot = last_plot(), width = 10, height = 6, dpi = 300)

# first 10 versus last 10

# repeat for the relevant experiments

# some stats

```

parallel versus perpendicular results

```{r}

# Tile plot ####
facet_labels <- c(thin_stripes = "multiple thin 45 degree stripes",
                          thick_stripe = "single thick stripe",
                          control = "control")

perp_para %>%
  filter(individual %in% c("13", "51", "53")) %>% 
  mutate(first = as.character(first),
                     individual = factor(individual, levels = 
                                              rev(c("13", "51", "53"))),
                   stimuli = factor(stimuli, levels = rev(c("test","ctrl")))) %>%
  ggplot(aes(y = stimuli, x = rank_trial, fill = first))+
  geom_tile()+
  facet_wrap(~ individual,  ncol = 1,
             labeller = labeller(individual = ~ paste("Individual: ", .),
                                 .multi_line = F),
             scales = "free_y")+
  labs(x = "Trial", y = "Experiment", fill = "Choice")+
  scale_fill_manual(values = c("0" = "#e41a1c", "1" = "#4daf4a"), 
                    breaks = c( "1","0"), 
                    labels = c("Rewarding", "Unrewarding"))+
  scale_y_discrete(labels = c("Control", "Test"))+
  theme_bw()+
  theme(panel.grid = element_blank(),
        legend.position = "top",
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14))
ggsave("figures//perppara_tileplot.png", plot = last_plot(), width = 6, height = 6, dpi = 300)


# point plot with confidence intervals ####

proportion_data <- perp_para %>%
  group_by(stimuli) %>%
  summarise(proportion_correct = mean(first, na.rm = T),
            n = n())
# Calculate the confidence intervals
alpha <- 0.95 # Confidence level
z_value <- qnorm((1 + alpha) / 2) # Z-value for confidence interval
proportion_data <- proportion_data %>%
  mutate(se = sqrt(proportion_correct * (1 - proportion_correct) / n),
         conf_interval = z_value * se)

proportion_data %>% 
  mutate(stimuli = factor(stimuli, levels = c("test","ctrl"))) %>%
ggplot(aes(x = stimuli, y = proportion_correct)) +
  geom_point(size = 3)+
  geom_hline(yintercept = 0.5, lty = 2)+
  scale_y_continuous(labels = scales::percent)+
      scale_x_discrete(labels = c("Test", "Control"))+
  geom_errorbar(aes(ymin = proportion_correct - conf_interval, ymax = proportion_correct + conf_interval),
                position = position_dodge(width = 0.8), width = 0.2) +
  labs(y = "Percent correct decisions") +
  theme_minimal()+
  theme(axis.title.x = element_blank(),  
        axis.title.y = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 14))+
ggsave("figures//perppara_point_and_errorbars.png", plot = last_plot(), width = 3, height = 3, dpi = 300)

# logistic regression with ggplot ####

test <- perp_para %>% filter(stimuli == "test")
ctrl <- perp_para %>% filter(stimuli == "ctrl")

m_test <- glm(first ~ rank_trial, data = test, family = binomial)
m_ctrl <- glm(first ~ rank_trial, data = ctrl, family = binomial)
summary(m_test)
summary(m_ctrl)

test$pred_prob <- predict(m_test, type = "response")
ctrl$pred_prob <- predict(m_ctrl, type = "response")

combined_data <- bind_rows(test %>% select(first, rank_trial, pred_prob),
                           ctrl %>% select(first, rank_trial, pred_prob))
combined_data %>% filter(stimuli == "test") %>% 
  ggplot(aes(x = rank_trial, y = pred_prob)) +
  geom_smooth(method = "loess", se = FALSE) +
  geom_smooth(method = "glm", method.args = list(family = binomial),
             colour = "black", fill = "grey", alpha = 0.2) +
  geom_hline(yintercept = 0.5, lty = 2)+
  labs(x = "Trial", y = "Predicted probability\ncorrect decision") +
  scale_color_manual(values = c("red", "green", "blue")) +
  theme_minimal()+
  theme(axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14))
ggsave("figures//perppara_log_reg.png", plot = last_plot(), width = 5, height = 3, dpi = 300)



```


## Things to think about
What is the effect of the blocking I've been doing? I haven't had a very firm or consistant rule about blocking except that I do it after an individual makes consistant mistakes in one direction and appears to have a side bias. I think its important to think about because its a very effective way to teach the wasp or to accelerate its learning. I use blocking with the intention of showing the wasp that it can turn the other direction and still receive the reward. I believe that insects might need to learn to override a consistant motor command, or perhaps to learn that varying the motor commands is more effective (more rewarding) than using one motor command exclusively. I think that the wasp might need to be shown that two paths exist and that one path always contains the reward. If the wasp is not shown this, then all it knows is that it is receiving rewards in a somewhat idiosyncratic way. Perhaps the wasp does 'notice' that the pattern overhead signifies the presence of reward or the lack thereof. But it surely doesn't know that the reward exists in the other arm when it is not present in this arm. How could it? Unless it has some in-built mechanism that informs steering commands when a snapshot is not matched. This makes me wonder, what happens if you just have one arm and change the patterns and reward? Will the wasp ever learn to turn around, or increase its turning around over time? Or can this only happen when the wasp also learns that there is another location to turn around and go to? 

If the wasp learns that there are two locations, does this heighten its sensitivity to the differences in the two dorsal patterns? I'm wondering if when there is only one arm / location the wasp is less sensitive to changes in the pattern because these changes can and do happen in nature.

- I should account for side bias in my analyses. One effect of side bias in combination with an unequal number of trials will be an over / underestimate of decision accuracy. How can I account for too many trials on one side? I need to weight the trials from each side equally...

- there are important decisions to make around which individuals to include seeing as some came into experiments at different times and may have had side preferences for longer. Im thinking #31 from recent experiments where I had too many individuals to give it proper attention and eradicate its side preference rapidly. One solution may be to analyze results with different subsets of individuals and to see whether it affects inferences.

- I wonder if its not just the accuracy of first decisions that changes when you chang from patterns to no patterns but also the total number of incorrect decisions? ie do they go the same, wrong way a lot more when no patterns in? What does this mean?

- humans can probably learn thousands of faces, insects can probably learn thousands of snapshots. can I learn anything from the human face recognition literature?

- i wouldnt jump to the conclusion that many thin stripes is more difficult than thick stripes just from this data because thick stripes had a training session not included in the data, which could bias the proportion correct upwards.

- is it really true that insects get better across trials? or is this just an effect of averaging across insects and rather there is a distinct moment that each insect 'gets it'? Would an interaction between trial and individual perhaps account for this? I haven't thought much about what the different models would be testing. 

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


TO DO:
0. enter data and plot previous experiments. particularly interested in seeing the first control. make note of the fact that training procedures have changed...
1. make tile plot for the cohort across thick stripe, multi small stripe and control. would be nice to annotate the onset of different days and experiments. 

INF. revisit logistic regression basics to understand the stats.

INF. visualize proportion correct of thick stripe, mulitple small stripes, and control.
next, think about logistic regression and learning rates.

INF. change name of 'choices' to reflect the experiment. eg. angled is a better name. If i'm still separating datasets by experiment.